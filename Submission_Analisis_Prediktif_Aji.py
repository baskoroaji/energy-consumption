# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_8b8eRqFUGfBIY21rqvNzNiQ35mFor4i

# Energy Consumption Dataset

# 1. Import Libraries

Mengimport Libraries yang dibutuhkan seperti
- pandas, numpy, seaborn, dan matplotlib untuk melakukan analisis data
- skicit learn untuk melakukan processing data, splitting data, dan algoritma machine learning seperti SVR, RandomForest, dan GradientBoosting, lalu metrics untuk mengetahui hasil apakah algoritma bagus atau tidak
- XGBoost dan LightGBM untuk algoritma machine learning yang dijalankan
"""

#Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
import lightgbm as lgb
from sklearn.svm import SVR

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.metrics import ConfusionMatrixDisplay

"""# 2. Data Understanding

1. Loading Data
Tujuannya untuk memuat data, mengeksplorasi tipe data, dan melihat angka seperti mean, quantil untuk dilakukan pemrosesan lebih lanjut saat cleaning data
"""

#Loading dataset
df = pd.read_csv('Energy_consumption.csv')
df.head()

"""# 3. Exploratory Data Analysis - Deskripsi Variabel"""

df.info()

df.describe()

"""Dari data yang disajikan terdapat 1000 kolom dan tidak terdapat missing value dan tidak ada anomali di dalam data seperti nilai yang sangat tinggi atau data yang tidak masuk akal

## deteksi missing value dan duplikasi
"""

#Deteksi Missing Values dan Duplikasi
print("Missing values per column:")
print(df.isnull().sum())
print("Duplicate rows:")
print(df.duplicated().sum())

"""Dari data yang disajikan diatas tidak terdapat missing value atau duplikasi yang berarti data sudah sangat bersih

## deteksi outliers
"""

#Deteksi Outliers
num_cols = df.select_dtypes(include='number').columns
print(num_cols)

for col in num_cols:
    plt.figure(figsize=(10, 5))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

"""dari data understanding diketahui bahwa data sudah sangat bersih terutama dari duplikasi atau missing value, akan tetapi ada data yang yang masih salah tipe data seperti timestamp yang seharusnya memiliki tipe data waktu, dan terdapat outlier pada energy consumption

# 4. Exploratory Data Analysis - Univariate Analysis

Sebelum melakukan ekstrasi timestamp perlu diketahui timestamp memiliki kesalahan tipe data oleh karena itu harus di ganti menjadi datetime

Melakukan pemisahan data pada timestamp agar mengetahui apakah ada faktor tambahan seperti tahun,bulan atau jam. Hari tidak dimasukan karena sudah merupakan fitur bawaan dari dataset
"""

#Mengubah Object ke Datetime
df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df.info()

#pemisahan Timestamp menjadi beberapa kolom tambahan
df['hour'] = df['Timestamp'].dt.hour
df['month'] = df['Timestamp'].dt.month
df['year'] = df['Timestamp'].dt.year
df.head()

"""# Eksplorasi Data Kategorikal
Eksplorasi Data Kategorikal untuk mencari Frekuensi dari data kategorikal
"""

nums_features = ['Temperature', 'Humidity', 'SquareFootage', 'Occupancy','RenewableEnergy', 'EnergyConsumption','hour', 'month', 'year']
cat_features = ['Holiday', 'DayOfWeek', 'HVACUsage', 'LightingUsage']

"""pemisihan fitur kategorikal dan numerikal bertujuan untuk memudahkan eksplorasi data"""

#Frekuensi Data Kategorikal Holiday
plt.figure(figsize=(8, 6))
plt.pie(df[cat_features[0]].value_counts(normalize=True), labels=df[cat_features[0]].unique(), autopct='%1.1f%%', startangle=140)
plt.title('Distribusi')
plt.axis('equal')
plt.show()

#Category Feature Day of Week
feature = cat_features[1]
count = df[feature].value_counts()
count.plot(kind='bar', title=feature)

#Cateogry Feature HVAC Usage
feature = cat_features[2]
count = df[feature].value_counts()
count.plot(kind='bar', title=feature)

#Category Feature Lightning Usage
feature = cat_features[3]
count = df[feature].value_counts()
count.plot(kind='bar', title=feature)

"""# Insight
Dari Data Kategorikal yang disajikan dapat disimpulkan bahwa
- frekuensi dari penggunaan energi tidak pada hari libur tetapi pada hari kerja
- frekuensi hari paling banyak ada pada hari jumat
- frekuensi penggunaan HVAC dan LightningUsage juga paling banyak adalah off

# Analisis Variable Numerik
- untuk mengetahui distribusi data numerik apakah normal atau skewed
- mendeteksi outliers
- dan untuk mengetahui rentang nilai setiap variabel numerik
"""

#For loop untuk analisis semua variable numerik
for col in nums_features:
    plt.figure(figsize=(10, 5))
    sns.histplot(data=df, x=col, bins=30, kde=True)
    plt.title(f'Distribusi {col}')
    plt.show()

"""# Insight
Dari data diatas
- terdapat data yang uniform distribution seperti pada hours
- data seperti temperature, humidity dan squarefootage hampir seperti uniform distribution tetapi sedikit skewed/miring karena ada peak di sebelah kanan atau kiri
- data pada month dan year sangat sedikit yang memiliki kemungkinan besar tidak akan dijadikan fitur tetapi harus adanya analisis lanjut seperti matriks korelasi

# Exploratory Data Analysis - Multivariate Analysis

Analisis multivariasi bertujuan untuk
- mencari data kategorikal yang digabungkan ke data numerikal untuk mencari insight apakah ada data yang mempengaruhi energi consumption
"""

#Membuat for loop untuk analisis multivariasi
for col in cat_features:
  sns.catplot(x=col, y="EnergyConsumption", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="Set3")
  plt.title("Rata-rata 'EnergyConsumption' Relatif terhadap - {}".format(col))

df.groupby('DayOfWeek')['EnergyConsumption'].sum().plot(kind='bar')

"""# Insight
Dari data yang disajikan terdapat beberapa fitur kategorikal yang mempengaruhi konsumsi energi seperti
- penggunaan HVAC(Heating, Ventilation, Air Conditioning) dalam kondisi on
- pengunaan lampu dalam kondisi off
- pengunaan yang paling besar adalah ketiga hari kerja dan bukan hari libur
- penggunaan yang paling besar ada di hari jumat

kesimpulannya penggunaan HVAC menjadi salah satu faktor karena banyaknya penggunaan HVAC, hari kerja juga menjadi salah satu faktor dimana hari jumat menjadi hari yang paling banyak menggunakan energi, walaupun pada data secara rata hari senin yang paling tinggi tetapi secara jumlah hari jumat lah dimana konsumsi tertinggi terjadi

"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[nums_features].corr().round(2)

# Untuk print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""# Insight
Dari matriks korelasi diatas terdapat bahwa
- konsumsi energi memiliki kaitan yang kuat dengan temperatur dan occupancy
- month dan year tidak terlalu berpengaruh dikarenakan hanya data hanya mengambil di tahun 2022 dan hanya pada bulan 1 dan awal bulan 2 saja

kesimpulan dengan eratnya kaitan temperatur dan konsumsi energi dapat dihubungkan dengan penggunaan HVAC dimana orang orang ketika temperatur panas atau dingin mereka menggunakan AC atau penghangat

#  Data Preparation

Sebelum data di training ada baiknya data harus dibersihkan, dinormalisasi, dan distandarisasi agar tidak ada kesalahan ketika modelling data

Sebelum memulai Data Preperation, ada baiknya mengcopy dataset agar dataset asli tidak berpengaruh. Jadi dataset yang digunakan untuk modelling merupakan dataset dummy
"""

df_dummy = df.copy()
df_dummy.head()

"""**Penanganan Outliers**

penganganan outliers berguna ketika melakukan modelling data dimana terkadang ada algoritma yang sensitif terhadap noise atau outliers
"""

#Menangani Outliers pada Energy Consumption

Q1 = df_dummy['EnergyConsumption'].quantile(0.25)
Q3 = df_dummy['EnergyConsumption'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_dummy = df_dummy[(df_dummy['EnergyConsumption'] >= lower_bound) & (df_dummy['EnergyConsumption'] <= upper_bound)]
df_dummy = df_dummy.reset_index(drop=True)

num_cols = df_dummy.select_dtypes(include='number').columns

for col in num_cols:
    plt.figure(figsize=(10, 5))
    sns.boxplot(x=df_dummy[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

df_dummy.drop(['Timestamp','month', 'year'], axis=1, inplace=True)
df_dummy.head()

"""Berdasarkan EDA yang dilakukan timestamp, month dan year merupakan variable yang tidak terlalu berguna ketika proses modelling maka dari itu melakukan drop pada variable tersebut menjadi langkah yang bagus

## One Hot Encoding

Setelah dilakukan salinan dataset menjadi dummy dataset data di pisahkan kembali dan di lakukan encoding dan di concat atau digabungkan ke dataset lalu kolom yang asli di drop agar tidak bertabrakan. Akan tetapi disini EnergyConsumption tidak dimasukan karena nanti itu akan menjadi variable tersendiri ketika melakukan modelling
"""

#Melakukan Encoding dengan OneHotEncoder ke fitur Categorical
nums_features = ['Temperature', 'Humidity', 'SquareFootage', 'Occupancy', 'RenewableEnergy', 'hour']
cat_features = ['Holiday', 'DayOfWeek', 'HVACUsage', 'LightingUsage']

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoded = encoder.fit_transform(df_dummy[cat_features])

encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(cat_features), index=df_dummy.index)

df_dummy = pd.concat([df_dummy, encoded_df], axis=1)

df_dummy.drop(columns=cat_features, inplace=True)

df_dummy.head()

"""# Standarisasi dengan StandardScaler

Berdasarkan EDA ada data yang sedikit skewed oleh karena itu dibutuhkannya standarisasi agar menjadi distribusi normal
"""

#Melakukan Standarisasi ke fitur numerical
scaler = StandardScaler()
df_dummy[nums_features] = scaler.fit_transform(df_dummy[nums_features])
df_dummy.head()

"""# Splitting Data

Splitting data digunakan untuk memisahkan data untuk training dan testing. Sebelum melakukan splitting data X dan Y harus ditentukan
- X : semua variable yang ada pada kolom kecuali EnergyConsumption
- Y : variable EnergyConsumption
karena tujuannya adalah untuk mencari prediksi konsumsi energi maka EnergyConsumption ada pada variable berbeda
"""

X = df_dummy.drop(['EnergyConsumption'], axis=1)
y = df_dummy['EnergyConsumption']

#splitting train dan test data menjadi 80 20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""# Modelling

Modelling menggunakan beberapa Algoritma:
- SVR : Support Vector Regressor
- RandomForest: Random Forest Regressor
- Gradient Boosting : Gradient Boosting Regressor
- XGBoost : XGB Regressor
- LightGBM : LGBM Regressor

semua algoritma menggunakan regressor karena ingin mencari prediksi secara regresi
"""

models = {
    'SVR': SVR(),
    'RandomForest': RandomForestRegressor(random_state=42),
    'GradientBoosting': GradientBoostingRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42),
    'LightGBM': lgb.LGBMRegressor(random_state=42)
}

"""Training menggunakan semua algoritma yang ada pada dictionary models lalu di simpan ke predictions dictionary untuk di evaluasi"""

predictions = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    predictions[name] = preds

"""# Evaluasi Metrik (MAE, RMSE, dan $R^2$)

Metriks Evaluasi ketika melakukan algoritma Regresi merupakan MAE, RMSE, dan $R^2$
"""

result_df = pd.DataFrame({
    'Actual': y_test.values
})
for name, preds in predictions.items():
    result_df[f'Predicted_{name}'] = preds

result_df.head()

"""# Visualisasi Prediksi"""

#visualisasi hasil prediksi dengan scatter plot
plt.figure(figsize=(12, 8))
for name in models.keys():
    sns.scatterplot(
        x=result_df['Actual'],
        y=result_df[f'Predicted_{name}'],
        label=name,
        alpha=0.6
    )

# Plot perfect prediction line
plt.plot([result_df['Actual'].min(), result_df['Actual'].max()],
         [result_df['Actual'].min(), result_df['Actual'].max()],
         'k--', label='Perfect Prediction')

plt.xlabel('Actual Energy Consumption')
plt.ylabel('Predicted')
plt.title('Predicted vs Actual for All Models')
plt.legend()
plt.grid(True)
plt.show()

#Memasukan Hasil dari result_df ke dalam metrics dictionary
metrics = {
    'Model': [],
    'MAE': [],
    'RMSE': [],
    'R2': []
}

for name in models.keys():
    y_pred = result_df[f'Predicted_{name}']
    mae = mean_absolute_error(result_df['Actual'], y_pred)
    rmse = mean_squared_error(result_df['Actual'], y_pred)
    r2 = r2_score(result_df['Actual'], y_pred)

    metrics['Model'].append(name)
    metrics['MAE'].append(mae)
    metrics['RMSE'].append(rmse)
    metrics['R2'].append(r2)

metrics_df = pd.DataFrame(metrics)
metrics_df

"""# Insight
Dari hasil evaluasi metriks didapatkan hasil yang lumayan memuaskan
- Hasil MAE lumayan bagus yaitu pada 4.xxx dimana semakin dekat ke 0 semakin bagus

- RMSE hasilnya masih kurang memuaskan dimana RMSE menunjukan hasil yang sangat besar tetapi perlu diketahui bahwa RMSE dihitung berdasarkan target variable jika target variable berada di angka 100an maka ini termasuk bagus

- R2 hasilnya lumayan bagus karena semakin mendekati ke angka 1 walaupun masih berada di tengah tengah atau di angka 5

# Visualisasi MAE RMSE dan $R^2$

bertujuan untuk memvisualisasikan evaluasi dari setiap algoritma yang digunakan
"""

plt.figure(figsize=(16, 5))

# MAE
plt.subplot(1, 3, 1)
sns.barplot(x='Model', y='MAE', data=metrics_df, palette='Blues_d')
plt.title('Mean Absolute Error')
plt.ylabel('MAE')
plt.xticks(rotation=45)

# RMSE
plt.subplot(1, 3, 2)
sns.barplot(x='Model', y='RMSE', data=metrics_df, palette='Oranges_d')
plt.title('Root Mean Squared Error')
plt.ylabel('RMSE')
plt.xticks(rotation=45)

# R² Score
plt.subplot(1, 3, 3)
sns.barplot(x='Model', y='R2', data=metrics_df, palette='Greens_d')
plt.title('R² Score')
plt.ylabel('R²')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

#menghitung relative MAE dan RMSE
mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred)
mean_target = y_test.mean()

print("Relative MAE (%):", mae / mean_target * 100)
print("Relative RMSE (%):", rmse / mean_target * 100)

"""# Insight
- Dari Visualisasi, Dapat disimpulkan secara overall SVR memiliki performa yang lebih bagus dari yang lain dimana secara RMSE dan R2 skor lebih tinggi dari algoritma lain walaupun memiliki nilai yang sedikit lebih tinggi dari Random Forest
- Relative MAE dan RMSE menunjukan bahwa dari semua algoritma MAE memiliki nilai yang kecil dimana hanya 5% yang berarti **sangat bagus** dan RMSE yang lumayan besar di angka 39% yang dimana harus dibutuhkannya tuning lagi

# Saran
harus adanya hyperparameter tuning disetiap algortima yang dijalankan agar menghasilkan hasil yang terbaik
"""

#Feature importance
model = RandomForestRegressor()
model.fit(X_train, y_train)

importances = model.feature_importances_
feature_names = X_train.columns

pd.Series(importances, index=feature_names).sort_values(ascending=True).plot(kind='barh', figsize=(10,6))
plt.title("Feature Importances (Random Forest)")
plt.show()

"""# Insight
berdasarkan feature importance dengan random forest dapat disimpulkan temperatur menjadi yang paling berpengaruh disusul oleh renewable energy,Occupancy, Humidity, SquareFootage, Hour, dan HVAC

# Kesimpulan
- Melonjaknya konsumsi energi salah satu faktor yang paling besar adalah temperatur dimana ketika temperatur panas atau dingin orang orang menyalakan HVAC yang mempengaruhi tingginya konsumsi energi selain itu occupancy dimana di satu bangunan terdapat banyak orang akan banyak juga yang menggunakan HVAC

- Model machine learning yang dibuat sudah cukup memuaskan walaupun belum bagus atau sempurna, sudah bisa memprediksi lonjakan permintaan energi dengan baik dengan SVR atau Suport Vector Regressor menjadi yang overall lebih baik dari algoritma lainnya.Saran kedepannya adalah menggunakan tuning hyperparameter
"""